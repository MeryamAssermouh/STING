{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9f6f36",
   "metadata": {},
   "source": [
    "# Priorisation de mails : Notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95781f",
   "metadata": {},
   "source": [
    "Ce notebook a pour objectif de construire un modèle de classification de mails d'une boite mails générique\n",
    "Il prend en entrée la base de donnée de mails ainsi que les critères des exploitants sous format excel et génère en sortie un modèle entrainé "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349594c",
   "metadata": {},
   "source": [
    "## Importer les librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2ee76f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "482820c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Analyse des données\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Traitement de données texte\n",
    "import nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Classification\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76df737",
   "metadata": {},
   "source": [
    "## Definir les variables spécifique à la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc08588c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\massermouh'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664bd325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# définir les fichiers d'entrée et les critères\n",
    "\n",
    "fichier_mails = '.\\Documents\\Priorisation de mails\\database_annotation.xlsx'\n",
    "fichier_critères = '.\\Documents\\Priorisation de mails\\critères exploitants.xlsx'\n",
    "\n",
    "xl_mails = pd.ExcelFile(fichier_mails, engine='openpyxl', )\n",
    "df_mails = xl_mails.parse('Sheet1')\n",
    "\n",
    "xl_critères = pd.ExcelFile(fichier_critères, engine='openpyxl', )\n",
    "df_critères = xl_critères.parse('Feuil1')\n",
    "\n",
    "#top senders : les scores vont varier de 0 à 3\n",
    "top_senders = df_critères['noms expéditeurs importants']\n",
    "top_senders.dropna(inplace=True)\n",
    "top_senders = top_senders.to_list()\n",
    "\n",
    "\n",
    "#mots clés métier : les scores vont varier de 0 à 4\n",
    "wording_metier = df_critères['mots métier importants']\n",
    "wording_metier.dropna(inplace=True)\n",
    "wording_metier = wording_metier.to_list()\n",
    "\n",
    "\n",
    "#mots clés d'importance/urgence : les scores vont varier de 0 à 4\n",
    "wording_importance = [\"important\",\"urgent\",\"risque\",\"erreur\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a34de5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Date_Sent</th>\n",
       "      <th>Body</th>\n",
       "      <th>From (address)</th>\n",
       "      <th>To (address)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9604</td>\n",
       "      <td>Re: PANNEAUX 321 en attente de servitude</td>\n",
       "      <td>2021-01-04 07:13:07</td>\n",
       "      <td>Bonjour Emmanuel et meilleurs voeux à tous pou...</td>\n",
       "      <td>franck.glarey@airbus.com</td>\n",
       "      <td>n16aeroparc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9603</td>\n",
       "      <td>RE: PANNEAUX 321 en attente de servitude</td>\n",
       "      <td>2021-01-04 07:26:56</td>\n",
       "      <td>Bonjour Franck, Le nécessaire sera fait afin d...</td>\n",
       "      <td>n16aeroparc@groupe-idea.com</td>\n",
       "      <td>GLAREY, FRANCK; n16aeroparc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   Subject           Date_Sent  \\\n",
       "0        9604  Re: PANNEAUX 321 en attente de servitude 2021-01-04 07:13:07   \n",
       "1        9603  RE: PANNEAUX 321 en attente de servitude 2021-01-04 07:26:56   \n",
       "\n",
       "                                                Body  \\\n",
       "0  Bonjour Emmanuel et meilleurs voeux à tous pou...   \n",
       "1  Bonjour Franck, Le nécessaire sera fait afin d...   \n",
       "\n",
       "                From (address)                 To (address)  \n",
       "0     franck.glarey@airbus.com                  n16aeroparc  \n",
       "1  n16aeroparc@groupe-idea.com  GLAREY, FRANCK; n16aeroparc  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_mails = df_mails.drop('0',axis=1)\n",
    "df_mails.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7238e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraire la base de données contenant que les mails reçus si besoin\n",
    "\n",
    "s ='n16aeroparc'\n",
    "mails_reçus = df_mails[df_mails['From (address)'].str.contains(s)==False]\n",
    "\n",
    "############ à compléter rec_df ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8fa3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6650"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mails_reçus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bd6016",
   "metadata": {},
   "source": [
    "## Annotation de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23bc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initier le dataframe qui va contenir ces critères\n",
    "\n",
    "scores = pd.DataFrame(columns=['top_senders', 'wording_metier', 'wording_importance','destinataires','majuscule','exclamation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b48ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplir le dataframe des critères\n",
    "\n",
    "for idx, row in mails_reçus.iterrows():\n",
    "    \n",
    "    score_senders = 0\n",
    "    w_metier = 0\n",
    "    w_importance = 0\n",
    "    destinataires = 0\n",
    "    maj = 0\n",
    "    exc = 0\n",
    "    l = []\n",
    "    \n",
    "    \n",
    "    #score top_senders\n",
    "    for x in top_senders :\n",
    "        #if row['From (address)'].__contains__(x):\n",
    "        if x in str(row['From (address)']).lower():\n",
    "            score_senders = score_senders + 1\n",
    "    l.append(score_senders)\n",
    "    \n",
    "    #score wording metier\n",
    "    for v in wording_metier :\n",
    "        if v in str(row['Subject']).lower():\n",
    "        #if row['Subject'].str.lower().str.contains(v):\n",
    "            w_metier = w_metier + 1\n",
    "        if v in str(row['Body']).lower():\n",
    "            w_metier = w_metier + 1\n",
    "    l.append(w_metier)\n",
    "    \n",
    "    #score wording_importance\n",
    "    for w in wording_importance :\n",
    "        if w in str(row['Subject']).lower():\n",
    "            w_importance = w_importance + 1\n",
    "        if w in str(row['Body']).lower():\n",
    "            w_importance = w_importance + 1\n",
    "    l.append(w_importance)\n",
    "    \n",
    "    #score nombre de destinataires\n",
    "    z = str(row['To (address)']).lower()\n",
    "    #z = replace_substring(z, s, '@IDEA')\n",
    "    if len(z)==0:\n",
    "        destinataires = 0\n",
    "    else :\n",
    "        destinataires = z.count(';') + 1\n",
    "    l.append(destinataires)\n",
    "    \n",
    "    #score mots majuscule\n",
    "    maj = sum(map(str.isupper, str(row['Body']).split())) + sum(map(str.isupper, str(row['Subject']).split()))\n",
    "    l.append(maj)\n",
    "    \n",
    "    #score nombre de points d'exclamation\n",
    "    a = str(row['Body']).lower()\n",
    "    b = str(row['Subject']).lower()\n",
    "    exc = a.count('!') + b.count('!')\n",
    "    l.append(exc)\n",
    "    \n",
    "    #ajout de la ligne qui correspont a ce row au dataframe \n",
    "    #print(len(scores))\n",
    "\n",
    "    scores.loc[len(scores)] = l\n",
    "\n",
    "#normalisation des scores \n",
    "\n",
    "scores['top_senders'] = scores['top_senders']/max(scores['top_senders'])\n",
    "scores['wording_metier'] = scores['wording_metier']/max(scores['wording_metier'])\n",
    "scores['wording_importance'] = scores['wording_importance']/max(scores['wording_importance'])\n",
    "scores['destinataires'] = scores['destinataires']/max(scores['destinataires'])\n",
    "scores['majuscule'] = scores['majuscule']/max(scores['majuscule'])\n",
    "scores['exclamation'] = scores['exclamation']/max(scores['exclamation'])\n",
    "\n",
    "# Calcul du score moyen pour chaque mail\n",
    "\n",
    "col = scores.loc[: , \"top_senders\":\"exclamation\"]\n",
    "scores['score_moyen'] = col.mean(axis=1)\n",
    "\n",
    "scores.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7501bd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.655e+03, 1.411e+03, 2.730e+02, 1.360e+02, 1.030e+02, 4.100e+01,\n",
       "        1.900e+01, 9.000e+00, 2.000e+00, 1.000e+00]),\n",
       " array([0.0021645 , 0.05434304, 0.10652157, 0.15870011, 0.21087865,\n",
       "        0.26305718, 0.31523572, 0.36741425, 0.41959279, 0.47177133,\n",
       "        0.52394986]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualiser la destribution des scores moyens\n",
    "\n",
    "plt.hist(list(scores['score_moyen']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c1bf48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(arr[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bca3c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mails pas importants :  4655\n",
      "nombre de mails importants :  1995\n"
     ]
    }
   ],
   "source": [
    "# méthode d'annotation 1 : on calcule le score moyen et on fait un tresholding \n",
    "\n",
    "tresh = 0.05434304\n",
    "\n",
    "sc = scores.copy()\n",
    "arr = sc.to_numpy()\n",
    "\n",
    "#print(arr.shape)\n",
    "\n",
    "for i in range(len(arr[:,-1])):\n",
    "    if arr[i,-1]<tresh :\n",
    "        arr[i,-1] = 0\n",
    "    else:\n",
    "        arr[i,-1] = 1\n",
    "\n",
    "print(\"nombre de mails pas importants : \",np.count_nonzero(arr[:,-1]==0))\n",
    "print(\"nombre de mails importants : \",np.count_nonzero(arr[:,-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d46bcb",
   "metadata": {},
   "source": [
    "## Génération des attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd6ac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6650 entries, 0 to 9603\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Unnamed: 0      6650 non-null   int64         \n",
      " 1   Subject         6641 non-null   object        \n",
      " 2   Date_Sent       6650 non-null   datetime64[ns]\n",
      " 3   Body            6584 non-null   object        \n",
      " 4   From (address)  6650 non-null   object        \n",
      " 5   To (address)    6643 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 363.7+ KB\n"
     ]
    }
   ],
   "source": [
    "mails_reçus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4f5189f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "Subject            9\n",
       "Date_Sent          0\n",
       "Body              66\n",
       "From (address)     0\n",
       "To (address)       7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails_reçus.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f0b0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mails_reçus['Body'] = mails_reçus['Body'].astype('string')\n",
    "mails_reçus['Subject'] = mails_reçus['Subject'].astype('string')\n",
    "mails_reçus['From (address)'] = mails_reçus['From (address)'].astype('string')\n",
    "mails_reçus['To (address)'] = mails_reçus['To (address)'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f20b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mails_reçus.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "248dc8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération des attributs non textuels\n",
    "\n",
    "crit = pd.DataFrame()\n",
    "\n",
    "# Création d'autres attributs non textuels :\n",
    "\n",
    "# 1 - longeur du mail\n",
    "\n",
    "crit[\"longeur\"] = mails_reçus['Body'].str.split().map(len)\n",
    "\n",
    "# 2 - Nombre de destinataires/copies\n",
    "\n",
    "nb_destinataires = []\n",
    "\n",
    "for element in mails_reçus['To (address)'] :\n",
    "    w = str(element).lower()\n",
    "    if len(w)==0:\n",
    "        dest = 0\n",
    "    else :\n",
    "        dest = w.count(';') + 1\n",
    "        \n",
    "    \n",
    "    nb_destinataires.append(dest)\n",
    "      \n",
    "\n",
    "crit = crit.assign(nombre_de_destinataires = nb_destinataires)\n",
    "\n",
    "# 3 - nombre de mots en majuscule\n",
    "\n",
    "mots_maj = []\n",
    "\n",
    "for idx, row in mails_reçus.iterrows():\n",
    "    maj = sum(map(str.isupper, str(row['Body']).split())) + sum(map(str.isupper, str(row['Subject']).split()))\n",
    "    mots_maj.append(maj)\n",
    "\n",
    "crit = crit.assign(mots_maj = mots_maj)\n",
    "\n",
    "#4 - nombre de lettres majuscules\n",
    "\n",
    "lettres_maj = []\n",
    "\n",
    "for idx, row in mails_reçus.iterrows():\n",
    "    maj = sum(i.isupper() for i in str(row['Body']))\n",
    "    lettres_maj.append(maj)\n",
    "\n",
    "crit = crit.assign(lettres_maj = lettres_maj)\n",
    "\n",
    "# 5 -  nombre de ponctuations\n",
    "punct_counts = []\n",
    "\n",
    "import string \n",
    "    \n",
    "punct = string.punctuation\n",
    "\n",
    "for idx, row in mails_reçus.iterrows():\n",
    "    punct_count = 0\n",
    "    for element in punct :\n",
    "        punct_count = punct_count + str(row['Body']).count(element)\n",
    "    punct_counts.append(punct_count)\n",
    "    \n",
    "crit = crit.assign(punct_counts = punct_counts)\n",
    "\n",
    "\n",
    "# # 6 -  nombre de points d'exclamation\n",
    "\n",
    "# pts_exclamation = []\n",
    "\n",
    "# for idx, row in df_mails.iterrows():\n",
    "#     a = str(row['Body']).lower()\n",
    "#     b = str(row['Subject']).lower()\n",
    "#     exc = a.count('!') + b.count('!')\n",
    "#     pts_exclamation.append(exc)\n",
    "\n",
    "# crit = crit.assign(pts_exclamation = pts_exclamation)\n",
    "\n",
    "# # 7 -  longeur moyenne du mot\n",
    "\n",
    "# from statistics import mean\n",
    "\n",
    "longueur_moy_mots = []\n",
    "\n",
    "for idx, row in mails_reçus.iterrows():\n",
    "    ls = [len(x) for x in str(row['Body']).split()]\n",
    "    longueur_moy_mots.append(np.mean(ls))\n",
    "\n",
    "crit = crit.assign(longueur_moy_mots = longueur_moy_mots)\n",
    "\n",
    "# 8 -  longeur moyenne de phrase\n",
    "# import re\n",
    "\n",
    "# longeur_moy_phrase = []\n",
    "\n",
    "# for idx, row in rec_df.iterrows():\n",
    "    \n",
    "#     new_body = str(row['Body']).replace('!', '.').replace('?', '.')\n",
    "#     split_list = new_body.split('.')\n",
    "#     k = [len(x.split()) for x in split_list]\n",
    "#     longeur_moy_phrase.append(np.mean(k))\n",
    "\n",
    "# crit = crit.assign(longeur_moy_phrase = longeur_moy_phrase)\n",
    "\n",
    "\n",
    "\n",
    "# # 9 -  ratio stop words\n",
    "\n",
    "ratios = []\n",
    "\n",
    "for idx, row in mails_reçus.iterrows():\n",
    "    \n",
    "    if len(str(row['Body']).split()) != 0:\n",
    "        \n",
    "        x = sum([str(row['Body']).split().count(x) for x in (set(stopwords.words('french')) | set(stopwords.words('english')))])/len(str(row['Body']).split())\n",
    "    \n",
    "        rat = x/len(str(row['Body']).split())\n",
    "        ratios.append(rat)\n",
    "    else :\n",
    "        ratios.append(0)\n",
    "\n",
    "crit = crit.assign(ratios = ratios)\n",
    "\n",
    "# # 10 - nombre de mots uniques\n",
    "\n",
    "uniques = []\n",
    "for idx, row in mails_reçus.iterrows():\n",
    "    uniques.append(len(set(str(row['Body']).split())))\n",
    "\n",
    "crit = crit.assign(uniques = uniques)\n",
    "\n",
    "# 11 -  nombre de digits\n",
    "\n",
    "nb_digits = []\n",
    "digits = list(range(10))\n",
    "\n",
    "for idx, row in mails_reçus.iterrows():\n",
    "    d = 0\n",
    "    for e in digits :\n",
    "        d = d + str(row['Body']).count(str(d))\n",
    "    nb_digits.append(d)\n",
    "    \n",
    "crit = crit.assign(nb_digits = nb_digits)    \n",
    "\n",
    "# 12 - nombre de mots contenants digits et lettres\n",
    "\n",
    "import string\n",
    "\n",
    "nb_ref = []\n",
    "\n",
    "for idx, row in mails_reçus.iterrows():\n",
    "    x = 0\n",
    "    for element in str(row['Body']).split() :\n",
    "        if len(set(list(element))&set(list(string.ascii_lowercase)))*len(set(list(range(10)))&set(list(element))) !=0 :\n",
    "            x = x + 1\n",
    "    nb_ref.append(x)\n",
    "\n",
    "crit = crit.assign(nb_ref = nb_ref)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05e4130d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6650, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dabe07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un dataframe avec une colonne texte contenant le body le sujet et les expéditeurs\n",
    "\n",
    "matrice = pd.DataFrame()\n",
    "matrice[\"text\"] = mails_reçus['From (address)'].astype(str) + mails_reçus[\"Subject\"].astype(str) + mails_reçus[\"Body\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eb21c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10396"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Génération des attributs textuels :\n",
    "\n",
    "messages = matrice[\"text\"]\n",
    "\n",
    "## Preprocessing : \n",
    "\n",
    "#Preprocess text messages\n",
    "\n",
    "# Replace URLs with 'webaddress'\n",
    "processed = messages.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'webaddress')\n",
    "\n",
    "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    \n",
    "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumbr')\n",
    "    \n",
    "# Replace numbers with 'numbr'\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "\n",
    "# Remove punctuation\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "\n",
    "# change words to lower case \n",
    "processed = processed.str.lower()\n",
    "\n",
    "# remove french stop words from text messages\n",
    "\n",
    "stop_words = set(stopwords.words('french'))\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))\n",
    "\n",
    "# remove english stop words from text messages\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# stop_words.add('bonjour')\n",
    "stop_words.add('please')\n",
    "stop_words.add('mailto')\n",
    "stop_words.add('mail')\n",
    "stop_words.add('numbr')\n",
    "# stop_words.add('cordialement')\n",
    "stop_words.add('e')\n",
    "stop_words.add('virus')\n",
    "stop_words.add('antiphishing')\n",
    "stop_words.add('merci')\n",
    "stop_words.add('com')\n",
    "stop_words.add('fr')\n",
    "stop_words.add('https')\n",
    "stop_words.add('bjenumbrywvybnumbrbhcmnaznumbrjvdxbllwlkzweuynumbrt')\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))\n",
    "\n",
    "#Appliquer la tf-idf pour trouver les mots contenus dans les mails avec leurs scores d'importance\n",
    "\n",
    "vect = TfidfVectorizer(max_df=0.50, min_df=2)\n",
    "X = vect.fit_transform(processed)\n",
    "len(vect.get_feature_names())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62f7f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.nan_to_num(X, posinf = 999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9f59035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fonctions utiles\n",
    "\n",
    "# finding the top keywords in the emails\n",
    "\n",
    "def top_tfidf_feats(row, features, top_n=20):\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats, columns=['features', 'score'])\n",
    "    return df\n",
    "def top_feats_in_doc(X, features, row_id, top_n=25):\n",
    "    row = np.squeeze(X[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)\n",
    "def top_mean_feats(X, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    if grp_ids:\n",
    "        D = X[grp_ids].toarray()\n",
    "    else:\n",
    "        D = X.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)\n",
    "\n",
    "# The find_features function will determine which of the 2000 word features are contained in the review\n",
    "\n",
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in feats:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "#Prendre les 2000 mots les plus importants comme attribus textuels\n",
    "\n",
    "features = vect.get_feature_names()\n",
    "#print(top_mean_feats(X, features, top_n=10))\n",
    "top_feats = top_mean_feats(X, features, top_n=2000)\n",
    "feats = top_feats['features']\n",
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be518180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créer la base de données des attributs combinés et la séparer en dataset de train et de test\n",
    "\n",
    "featuresets = [find_features(text) for text in processed]\n",
    "crit_text = pd.DataFrame.from_dict(featuresets)\n",
    "crit_all = pd.concat([crit.reset_index(drop=True),crit_text.reset_index(drop=True)], axis=1)\n",
    "crit_all = crit_all.replace([np.inf, -np.inf,np.nan], 0)\n",
    "crit_all = crit_all.reset_index()\n",
    "records = crit_all.to_dict('records')\n",
    "y = arr[:,-1]\n",
    "Z = [(records[i], y[i]) for i in range(0, len(records))]\n",
    "\n",
    "all_indices = list(range(len(Z)))\n",
    "\n",
    "train_indices, test_indices = model_selection.train_test_split(all_indices, test_size = 0.25, random_state = 42)\n",
    "\n",
    "#print(train_indices)\n",
    "training = [Z[i] for i in train_indices]\n",
    "testing = [Z[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c253ac",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a708657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 90.55923030667469\n"
     ]
    }
   ],
   "source": [
    "#Classification avec l'algorithme random forest \n",
    "\n",
    "model = SklearnClassifier(RandomForestClassifier())\n",
    "\n",
    "# train the model on the training data\n",
    "model.train(training)\n",
    "\n",
    "# and test on the testing dataset!\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"Random Forest Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c2189a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5f734d5",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "245a1ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Documents/Priorisation de mails/model_magasinX.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = './Documents/Priorisation de mails/model_magasinX.joblib'\n",
    "joblib.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543ae88",
   "metadata": {},
   "source": [
    "## Saving the textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc163c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./Documents/Priorisation de mails/features_magasinX.npy\", list(feats))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
